{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OleksandrZadvornyi/weather-forecasting/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytmyj-y6ineR",
        "outputId": "1fece00a-2deb-451b-9b68-403ecaab2975"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sdivx5UdGvLD"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh3dzM8ikjpD",
        "outputId": "c8f21bf6-82f6-43ae-b5a4-18ca5e5b4ed8"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J9mAzVNkg7a",
        "outputId": "8cba96ae-73fc-48fd-a603-30e5fe87e26d"
      },
      "outputs": [],
      "source": [
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J-OdzqYkfIe",
        "outputId": "faf7f8c5-f64f-4300-d438-11eed91de090"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVpJxNQokXmi",
        "outputId": "a4dbb09a-009e-483e-e14f-1487e7cb225e"
      },
      "outputs": [],
      "source": [
        "!pip install -q gluonts ujson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqxi5QYHksaa",
        "outputId": "853a6f0e-32c0-49a3-c51e-c3ce7623dd0b"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "# Load datasets\n",
        "data_dir = \"/content/drive/MyDrive/weather_forecasting_project/prepared_datasets\"\n",
        "\n",
        "dataset = load_from_disk(f\"{data_dir}/dataset\")\n",
        "\n",
        "print(f\"Train dataset: {len(dataset['train'])} time series\")\n",
        "print(f\"Validation dataset: {len(dataset['validation'])} time series\")\n",
        "print(f\"Test dataset: {len(dataset['test'])} time series\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmFOh2m-k6xN",
        "outputId": "435d41fa-0d2b-4f96-d0fa-b7e8338178f1"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YhNQIx6k99F",
        "outputId": "09a0ee5c-4a5b-4715-eb25-412f3e484c58"
      },
      "outputs": [],
      "source": [
        "train_example = dataset[\"train\"][0]\n",
        "train_example.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM0J4PholAcN",
        "outputId": "6c88848e-a270-41d8-dbd9-ee70b9d1700a"
      },
      "outputs": [],
      "source": [
        "print(train_example[\"start\"])\n",
        "print(train_example[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFhs9U28lMr9",
        "outputId": "a709987d-0e2a-4d13-880f-1c7a2511f31e"
      },
      "outputs": [],
      "source": [
        "validation_example = dataset[\"validation\"][0]\n",
        "validation_example.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnf1CXDNlQim",
        "outputId": "fdedea2e-6bea-4b19-e1ec-f9b44325071c"
      },
      "outputs": [],
      "source": [
        "print(validation_example[\"start\"])\n",
        "print(validation_example[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "RJl97U22lSqj"
      },
      "outputs": [],
      "source": [
        "freq = \"1D\"\n",
        "prediction_length = 30\n",
        "\n",
        "#assert len(train_example[\"target\"]) + prediction_length == len(\n",
        "#    validation_example[\"target\"]\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "J6zOS9GolgUg",
        "outputId": "fa95aa91-2233-41d2-d67d-b679096f9298"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure, axes = plt.subplots()\n",
        "axes.plot(train_example[\"target\"], color=\"blue\")\n",
        "axes.plot(validation_example[\"target\"], color=\"red\", alpha=0.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bpM-10kOlpkk"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2hDiPNiXlssU"
      },
      "outputs": [],
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "@lru_cache(10_000)\n",
        "def convert_to_pandas_period(date, freq):\n",
        "    return pd.Period(date, freq)\n",
        "\n",
        "def transform_start_field(batch, freq):\n",
        "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DUv-C6chnYUv"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
        "test_dataset.set_transform(partial(transform_start_field, freq=freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIaScMUTnlcA",
        "outputId": "95281dd8-d62e-4c2b-d13e-807173c8fc24"
      },
      "outputs": [],
      "source": [
        "from gluonts.time_feature import get_lags_for_frequency\n",
        "\n",
        "lags_sequence = get_lags_for_frequency(freq)\n",
        "print(lags_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxIcQiw_npan",
        "outputId": "d25284f7-3b3a-4d63-87ec-32afa838303c"
      },
      "outputs": [],
      "source": [
        "from gluonts.time_feature import time_features_from_frequency_str\n",
        "\n",
        "time_features = time_features_from_frequency_str(freq)\n",
        "print(time_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Cdq62GYEn7i_"
      },
      "outputs": [],
      "source": [
        "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
        "\n",
        "config = TimeSeriesTransformerConfig(\n",
        "    prediction_length=prediction_length,\n",
        "    context_length=prediction_length * 2,\n",
        "    lags_sequence=lags_sequence,\n",
        "    num_time_features=len(time_features) + 1,  # Add 1 for age feature\n",
        "    num_static_categorical_features=1,\n",
        "    num_static_real_features=3,  # Latitude, longitude, elevation\n",
        "    cardinality=[len(train_dataset)],  # Number of unique time series\n",
        "    embedding_dimension=[2],  # Dimension of categorical embedding\n",
        "\n",
        "    encoder_layers=4,\n",
        "    decoder_layers=4,\n",
        "    d_model=64,\n",
        ")\n",
        "\n",
        "model = TimeSeriesTransformerForPrediction(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h9ONBEnOoXKj",
        "outputId": "7ca1372e-2b59-4ee3-d2cf-afd1d616bdd7"
      },
      "outputs": [],
      "source": [
        "model.config.distribution_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QhZT5t1rocyE"
      },
      "outputs": [],
      "source": [
        "from gluonts.time_feature import (\n",
        "    time_features_from_frequency_str,\n",
        "    TimeFeature,\n",
        "    get_lags_for_frequency,\n",
        ")\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.transform import (\n",
        "    AddAgeFeature,\n",
        "    AddObservedValuesIndicator,\n",
        "    AddTimeFeatures,\n",
        "    AsNumpyArray,\n",
        "    Chain,\n",
        "    ExpectedNumInstanceSampler,\n",
        "    InstanceSplitter,\n",
        "    RemoveFields,\n",
        "    SelectFields,\n",
        "    SetField,\n",
        "    TestSplitSampler,\n",
        "    Transformation,\n",
        "    ValidationSplitSampler,\n",
        "    VstackFeatures,\n",
        "    RenameFields,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oE9RZOZVopRh"
      },
      "outputs": [],
      "source": [
        "from transformers import PretrainedConfig\n",
        "\n",
        "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
        "    remove_field_names = []\n",
        "    if config.num_static_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
        "    if config.num_dynamic_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
        "    if config.num_static_categorical_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
        "\n",
        "    return Chain(\n",
        "        [RemoveFields(field_names=remove_field_names)]\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_CAT,\n",
        "                    expected_ndim=1,\n",
        "                    dtype=int,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_REAL,\n",
        "                    expected_ndim=1,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_real_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + [\n",
        "            AsNumpyArray(\n",
        "                field=FieldName.TARGET,\n",
        "                expected_ndim=1 if config.input_size == 1 else 2,\n",
        "            ),\n",
        "            AddObservedValuesIndicator(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.OBSERVED_VALUES,\n",
        "            ),\n",
        "            AddTimeFeatures(\n",
        "                start_field=FieldName.START,\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                time_features=time_features_from_frequency_str(freq),\n",
        "                pred_length=config.prediction_length,\n",
        "            ),\n",
        "            AddAgeFeature(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_AGE,\n",
        "                pred_length=config.prediction_length,\n",
        "                log_scale=True,\n",
        "            ),\n",
        "            VstackFeatures(\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
        "                + (\n",
        "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
        "                    if config.num_dynamic_real_features > 0\n",
        "                    else []\n",
        "                ),\n",
        "            ),\n",
        "            RenameFields(\n",
        "                mapping={\n",
        "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
        "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
        "                    FieldName.FEAT_TIME: \"time_features\",\n",
        "                    FieldName.TARGET: \"values\",\n",
        "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
        "                }\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WvipGZutozCB"
      },
      "outputs": [],
      "source": [
        "from gluonts.transform.sampler import InstanceSampler\n",
        "from typing import Optional\n",
        "\n",
        "def create_instance_splitter(\n",
        "    config: PretrainedConfig,\n",
        "    mode: str,\n",
        "    train_sampler: Optional[InstanceSampler] = None,\n",
        "    validation_sampler: Optional[InstanceSampler] = None,\n",
        ") -> Transformation:\n",
        "    assert mode in [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    instance_sampler = {\n",
        "        \"train\": train_sampler\n",
        "        or ExpectedNumInstanceSampler(\n",
        "            num_instances=1.0, min_future=config.prediction_length\n",
        "        ),\n",
        "        \"validation\": validation_sampler\n",
        "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
        "        \"test\": TestSplitSampler(),\n",
        "    }[mode]\n",
        "\n",
        "    return InstanceSplitter(\n",
        "        target_field=\"values\",\n",
        "        is_pad_field=FieldName.IS_PAD,\n",
        "        start_field=FieldName.START,\n",
        "        forecast_start_field=FieldName.FORECAST_START,\n",
        "        instance_sampler=instance_sampler,\n",
        "        past_length=config.context_length + max(config.lags_sequence),\n",
        "        future_length=config.prediction_length,\n",
        "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "haEriMmqo6As"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "import torch\n",
        "from gluonts.itertools import Cached, Cyclic\n",
        "from gluonts.dataset.loader import as_stacked_batches\n",
        "\n",
        "def create_train_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    num_batches_per_epoch: int,\n",
        "    shuffle_buffer_length: Optional[int] = None,\n",
        "    cache_data: bool = True,\n",
        "    **kwargs,\n",
        ") -> Iterable:\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
        "        \"future_values\",\n",
        "        \"future_observed_mask\",\n",
        "    ]\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data, is_train=True)\n",
        "    if cache_data:\n",
        "        transformed_data = Cached(transformed_data)\n",
        "\n",
        "    instance_splitter = create_instance_splitter(config, \"train\")\n",
        "\n",
        "    stream = Cyclic(transformed_data).stream()\n",
        "    training_instances = instance_splitter.apply(stream)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        training_instances,\n",
        "        batch_size=batch_size,\n",
        "        shuffle_buffer_length=shuffle_buffer_length,\n",
        "        field_names=TRAINING_INPUT_NAMES,\n",
        "        output_type=torch.tensor,\n",
        "        num_batches_per_epoch=num_batches_per_epoch,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "15pcikAdpX-x"
      },
      "outputs": [],
      "source": [
        "def create_backtest_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    **kwargs,\n",
        "):\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data)\n",
        "\n",
        "    # We create a Validation Instance splitter which will sample the very last\n",
        "    # context window seen during training only for the encoder.\n",
        "    instance_sampler = create_instance_splitter(config, \"validation\")\n",
        "\n",
        "    # we apply the transformations in train mode\n",
        "    testing_instances = instance_sampler.apply(transformed_data, is_train=True)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        testing_instances,\n",
        "        batch_size=batch_size,\n",
        "        output_type=torch.tensor,\n",
        "        field_names=PREDICTION_INPUT_NAMES,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gFTQv30UpLwY"
      },
      "outputs": [],
      "source": [
        "train_dataloader = create_train_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=train_dataset,\n",
        "    batch_size=256,\n",
        "    num_batches_per_epoch=100,\n",
        ")\n",
        "\n",
        "test_dataloader = create_backtest_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=test_dataset,\n",
        "    batch_size=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAP7KkRepgoo",
        "outputId": "0af7c813-8607-4c8f-81ec-aedc3be10d21"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "for k, v in batch.items():\n",
        "    print(k, v.shape, v.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6th9DZ47p-4C"
      },
      "outputs": [],
      "source": [
        "# perform forward pass\n",
        "outputs = model(\n",
        "    past_values=batch[\"past_values\"],\n",
        "    past_time_features=batch[\"past_time_features\"],\n",
        "    past_observed_mask=batch[\"past_observed_mask\"],\n",
        "    static_categorical_features=batch[\"static_categorical_features\"]\n",
        "    if config.num_static_categorical_features > 0\n",
        "    else None,\n",
        "    static_real_features=batch[\"static_real_features\"]\n",
        "    if config.num_static_real_features > 0\n",
        "    else None,\n",
        "    future_values=batch[\"future_values\"],\n",
        "    future_time_features=batch[\"future_time_features\"],\n",
        "    future_observed_mask=batch[\"future_observed_mask\"],\n",
        "    output_hidden_states=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01wY5AxJqHIq",
        "outputId": "573ceecf-eb80-434a-df1a-443d316313a7"
      },
      "outputs": [],
      "source": [
        "print(\"Loss:\", outputs.loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eul86ODxGD5B",
        "outputId": "46b86fdf-defe-4070-e6d5-db1f505a382a"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "\n",
        "accelerator = Accelerator()\n",
        "device = accelerator.device\n",
        "\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
        "\n",
        "model, optimizer, train_dataloader = accelerator.prepare(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(40):\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else None,\n",
        "            static_real_features=batch[\"static_real_features\"].to(device)\n",
        "            if config.num_static_real_features > 0\n",
        "            else None,\n",
        "            past_time_features=batch[\"past_time_features\"].to(device),\n",
        "            past_values=batch[\"past_values\"].to(device),\n",
        "            future_time_features=batch[\"future_time_features\"].to(device),\n",
        "            future_values=batch[\"future_values\"].to(device),\n",
        "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
        "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Epoch {epoch}, Batch {idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / num_batches\n",
        "    print(f\"Epoch {epoch} completed. Average loss: {avg_epoch_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh1H3glRVRKI",
        "outputId": "e2346b59-5ad1-4a3b-8eb8-148b4da1d3f5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Load metadata\n",
        "with open(f\"{data_dir}/metadata.txt\", \"r\") as f:\n",
        "    metadata = {}\n",
        "    for line in f:\n",
        "        key, value = line.strip().split(\"=\")\n",
        "        metadata[key] = value\n",
        "\n",
        "target_column = metadata.get(\"target_column\", \"TMAX\")\n",
        "\n",
        "# Save the model and configuration\n",
        "model_path = \"/content/drive/MyDrive/weather_forecasting_project/weather_model\"\n",
        "config_path = \"/content/drive/MyDrive/weather_forecasting_project/weather_model/config\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    shutil.rmtree(model_path)\n",
        "\n",
        "if os.path.exists(config_path):\n",
        "    shutil.rmtree(config_path)\n",
        "\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "\n",
        "# Get the unwrapped model if using accelerator\n",
        "unwrapped_model = accelerator.unwrap_model(model)\n",
        "\n",
        "# Save model state dictionary\n",
        "torch.save(unwrapped_model.state_dict(), os.path.join(model_path, \"time_series_model.pth\"))\n",
        "\n",
        "# Save the configuration\n",
        "unwrapped_model.config.to_json_file(os.path.join(config_path, \"config.json\"))\n",
        "\n",
        "# Save frequency and prediction length for later use\n",
        "with open(os.path.join(config_path, \"metadata.txt\"), \"w\") as f:\n",
        "    f.write(f\"freq={freq}\\n\")\n",
        "    f.write(f\"prediction_length={prediction_length}\\n\")\n",
        "    f.write(f\"target_column={target_column}\\n\")\n",
        "    f.write(f\"lags_sequence={lags_sequence}\\n\")\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n",
        "print(f\"Configuration saved to {config_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
